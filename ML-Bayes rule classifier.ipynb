{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Estimation assuming Gaussian Distribution followed by Bayes Rule for classification\n",
    "\n",
    "#### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils import mnist_reader\n",
    "X_train, y_train = mnist_reader.load_mnist('data/fashion', kind='train')\n",
    "X_test, y_test = mnist_reader.load_mnist('data/fashion', kind='t10k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixing the ill dimensions and flattening the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: (60000, 784)\n",
      "Number of training labels: (60000,)\n",
      "Number of testing images: (10000, 784)\n",
      "Number of testing labels: (10000,)\n",
      "Number of training images: (60000, 784)\n",
      "Number of training labels: (60000, 1)\n",
      "Number of testing images: (10000, 784)\n",
      "Number of testing labels: (10000, 1)\n",
      "The matrix used for calculation\n",
      "Number of training images: (784, 60000)\n",
      "Number of training labels: (1, 60000)\n",
      "Number of testing images: (784, 10000)\n",
      "Number of testing labels: (1, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Initial dimensions of the vectors\n",
    "print('Number of training images:', X_train.shape)\n",
    "print('Number of training labels:', y_train.shape)\n",
    "\n",
    "print('Number of testing images:', X_test.shape)\n",
    "print('Number of testing labels:', y_test.shape)\n",
    "\n",
    "Y_train = (y_train.reshape((X_train.shape[0]),1))\n",
    "Y_test = (y_test.reshape((X_test.shape[0]),1))\n",
    "\n",
    "print('Number of training images:', X_train.shape)\n",
    "print('Number of training labels:', Y_train.shape)\n",
    "\n",
    "print('Number of testing images:', X_test.shape)\n",
    "print('Number of testing labels:', Y_test.shape)\n",
    "\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "X_trainC = X_train.T\n",
    "X_testC = X_test.T\n",
    "Y_testC = Y_test.T\n",
    "Y_trainC = Y_train.T\n",
    "\n",
    "print(\"The matrix used for calculation\")\n",
    "print('Number of training images:', X_trainC.shape)\n",
    "print('Number of training labels:', Y_trainC.shape)\n",
    "\n",
    "print('Number of testing images:', X_testC.shape)\n",
    "print('Number of testing labels:', Y_testC.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the mean function which returns the mean and covariance matrix of a given class from the training set gives ans input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(trainDataset): #784 x 6000\n",
    "    mean = []\n",
    "    covm = np.cov(trainDataset)\n",
    "    trainDataset = np.array(trainDataset)\n",
    "    for index in range (0,trainDataset.shape[0]):\n",
    "        mean.append(np.mean(trainDataset[index]))\n",
    "    mean = np.array(mean)\n",
    "    mean = mean.reshape(mean.shape[0],1)\n",
    "    #print(covm)\n",
    "    #print(covm.shape)\n",
    "    #print(mean.shape)\n",
    "    return mean, covm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segregating the training classes based on the training labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 0.5*np.identity(784)\n",
    "count = 0\n",
    "train = []\n",
    "m = []\n",
    "c = []\n",
    "mean_for_all_class = []\n",
    "cov_for_all_class = []\n",
    "i = 0\n",
    "for lab in range(0,10):\n",
    "    while (i != X_train.shape[0]):\n",
    "        if Y_train[i] == lab:\n",
    "            count = count +1\n",
    "            train.append(X_train[i])\n",
    "        i = i+1\n",
    "    train = np.array(train)\n",
    "    m, c = mean(train.T)\n",
    "    c= c+ id\n",
    "    mean_for_all_class.append(m)\n",
    "    cov_for_all_class.append(c)\n",
    "    #print(train.shape)\n",
    "    train = []\n",
    "    i = 0\n",
    "    count = 0\n",
    "mean_for_all_class = np.array(mean_for_all_class) #10,784,1\n",
    "cov_for_all_class = np.array(cov_for_all_class) #10,784,784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 1)\n"
     ]
    }
   ],
   "source": [
    "print(mean_for_all_class[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining pdf function to get the value for each test sample, based on which bayes rule for classification is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf(sample, mean, covariance): #784,1   784,1   784,784\n",
    "    x = np.subtract(sample, mean)\n",
    "    #print(x.shape)\n",
    "    #print(x.T.shape)\n",
    "    y = np.matmul(x.T, np.linalg.inv(covariance))\n",
    "    #print('**',y.shape)\n",
    "    y = np.dot(y,x) \n",
    "    #print('****',y.shape)\n",
    "    z = (-0.5*y)-(0.5*np.log(np.linalg.det(covariance)))\n",
    "    #print(z)\n",
    "    return z\n",
    "#pdf(X_test[3],mean_for_all_class[3],cov_for_all_class[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal ML + Bayes rule of classification (with 784 dimension for each test sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd = []\n",
    "comp = 0\n",
    "baye = []\n",
    "for limit in range(0,X_test.shape[0]):\n",
    "    for ind in range(0,10):\n",
    "        X_test2 = X_test[limit].reshape(X_test[limit].shape[0],1)\n",
    "        #print(X_test2.shape)\n",
    "        #print(mean_for_all_class[ind].shape)\n",
    "        #print(cov_for_all_class[ind].shape)\n",
    "        p = pdf(X_test2,mean_for_all_class[ind],cov_for_all_class[ind])\n",
    "        if p[0]>comp:\n",
    "            comp = p[0]\n",
    "            label = ind\n",
    "    baye.append(label)\n",
    "    #print(baye)\n",
    "    comp = 0\n",
    "    #print(limit)\n",
    "#print(len(baye))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is-  74.47\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "eff = 0\n",
    "for loop in range(0,Y_test.shape[0]):\n",
    "    if baye[loop]==Y_test[loop]:\n",
    "        eff = eff + 1\n",
    "print('The accuracy is- ',(eff*100)/Y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing the dimension using PCA and going through the same pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original train shape:    (60000, 784)\n",
      "transformed train shape: (60000, 50)\n",
      "0.8626437338081597\n",
      "original test shape:    (10000, 784)\n",
      "transformed test shape: (10000, 50)\n"
     ]
    }
   ],
   "source": [
    "# using PCA for the ML - bays classifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=50) # reducing the dimension from 784 to 50\n",
    "# pca.fit(X_train)\n",
    "X_pca_train = pca.fit_transform(X_train)\n",
    "print(\"original train shape:   \", X_train.shape)\n",
    "print(\"transformed train shape:\", X_pca_train.shape)\n",
    "print(np.sum(pca.explained_variance_ratio_))\n",
    "# pca.fit(X_test)\n",
    "X_pca_test = pca.transform(X_test)\n",
    "print(\"original test shape:   \", X_test.shape)\n",
    "print(\"transformed test shape:\", X_pca_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#id = 0.5*np.identity(50)\n",
    "train_pca = []\n",
    "m_pca = []\n",
    "c_pca = []\n",
    "mean_for_all_class_pca = []\n",
    "cov_for_all_class_pca = []\n",
    "i = 0\n",
    "for lab_pca in range(0,10):\n",
    "    while (i != X_pca_train.shape[0]):\n",
    "        if Y_train[i] == lab_pca:\n",
    "            train_pca.append(X_pca_train[i])\n",
    "        i = i+1\n",
    "    train_pca = np.array(train_pca)\n",
    "    m_pca, c_pca = mean(train_pca.T)\n",
    "    #c_pca= c_pca+ id\n",
    "    mean_for_all_class_pca.append(m_pca)\n",
    "    cov_for_all_class_pca.append(c_pca)\n",
    "    #print(train.shape)\n",
    "    train_pca = []\n",
    "    i = 0\n",
    "mean_for_all_class_pca = np.array(mean_for_all_class_pca) #10,784,1\n",
    "cov_for_all_class_pca = np.array(cov_for_all_class_pca) #10,784,784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(mean_for_all_class_pca.shape)\n",
    "#print(np.sum(np.linalg.det(cov_for_all_class_pca)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_pca = 0\n",
    "baye_pca = []\n",
    "for limit_pca in range(0,X_pca_test.shape[0]):\n",
    "    for ind_pca in range(0,10):\n",
    "        X_test2_pca = X_pca_test[limit_pca].reshape(X_pca_test[limit_pca].shape[0],1)\n",
    "        #print(X_test2.shape)\n",
    "        #print(mean_for_all_class[ind].shape)\n",
    "        #print(cov_for_all_class[ind].shape)\n",
    "        p_pca = pdf(X_test2_pca,mean_for_all_class_pca[ind_pca],cov_for_all_class_pca[ind_pca])\n",
    "        #print(p_pca[0]+500)\n",
    "        if p_pca[0]+500>comp_pca:\n",
    "            comp_pca = p_pca[0]+500\n",
    "            label_pca = ind_pca\n",
    "    baye_pca.append(label_pca)\n",
    "    #print(baye_pca)\n",
    "    comp_pca = 0\n",
    "    #print(limit_pca)\n",
    "#print(len(baye_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is-  79.93\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "eff = 0\n",
    "for loop_pca in range(0,Y_test.shape[0]):\n",
    "    if baye_pca[loop_pca]==Y_test[loop_pca]:\n",
    "        eff = eff + 1\n",
    "print('The accuracy is- ',(eff*100)/Y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing the dimension from 50 to 9 usning LDA and giving the PCA data as input and going through the same pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original train shape:    (60000, 50)\n",
      "transformed train shape: (60000, 9)\n",
      "original test shape:    (10000, 50)\n",
      "transformed test shape: (10000, 9)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "X_lda_train = lda.fit_transform(X_pca_train,y_train)\n",
    "X_lda_test = lda.fit_transform(X_pca_test,y_test)\n",
    "\n",
    "print(\"original train shape:   \", X_pca_train.shape)\n",
    "print(\"transformed train shape:\", X_lda_train.shape)\n",
    "\n",
    "print(\"original test shape:   \", X_pca_test.shape)\n",
    "print(\"transformed test shape:\", X_lda_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#id = 0.5*np.identity(784)\n",
    "train_lda = []\n",
    "m_lda = []\n",
    "c_lda = []\n",
    "mean_for_all_class_lda = []\n",
    "cov_for_all_class_lda = []\n",
    "i = 0\n",
    "for lab_lda in range(0,10):\n",
    "    while (i != X_lda_train.shape[0]):\n",
    "        if Y_train[i] == lab_lda:\n",
    "            train_lda.append(X_lda_train[i])\n",
    "        i = i+1\n",
    "    train_lda = np.array(train_lda)\n",
    "    m_lda, c_lda = mean(train_lda.T)\n",
    "    #c= c+ id\n",
    "    mean_for_all_class_lda.append(m_lda)\n",
    "    cov_for_all_class_lda.append(c_lda)\n",
    "    #print(train.shape)\n",
    "    train_lda = []\n",
    "    i = 0\n",
    "mean_for_all_class_lda = np.array(mean_for_all_class_lda) #10,784,1\n",
    "cov_for_all_class_lda = np.array(cov_for_all_class_lda) #10,784,784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing some datas to confirm the right path\n",
    "#print(mean_for_all_class_lda.shape)\n",
    "#print(np.linalg.det(cov_for_all_class_lda[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_lda = 0\n",
    "baye_lda = []\n",
    "for limit_lda in range(0,X_lda_test.shape[0]):\n",
    "    for ind_lda in range(0,10):\n",
    "        X_test2_lda = X_lda_test[limit_lda].reshape(X_lda_test[limit_lda].shape[0],1)\n",
    "        #print(X_test2.shape)\n",
    "        #print(mean_for_all_class[ind].shape)\n",
    "        #print(cov_for_all_class[ind].shape)\n",
    "        p_lda = pdf(X_test2_lda,mean_for_all_class_lda[ind_lda],cov_for_all_class_lda[ind_lda])\n",
    "        #print(p_pca[0]+1000)\n",
    "        if p_lda[0]+500>comp_lda:\n",
    "            comp_lda = p_lda[0]+500\n",
    "            label_lda = ind_lda\n",
    "    baye_lda.append(label_lda)\n",
    "    #print(baye_lda)\n",
    "    comp_lda = 0\n",
    "    #print(limit_lda)\n",
    "#print(len(baye_lda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is-  80.0\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "eff = 0\n",
    "for loop_lda in range(0,Y_test.shape[0]):\n",
    "    if baye_lda[loop_lda]==Y_test[loop_lda]:\n",
    "        eff = eff + 1\n",
    "print('The accuracy is- ',(eff*100)/Y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
