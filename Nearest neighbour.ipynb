{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbour rule for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from utils import mnist_reader\n",
    "X_train, y_train = mnist_reader.load_mnist('data/fashion', kind='train')\n",
    "X_test, y_test = mnist_reader.load_mnist('data/fashion', kind='t10k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixing the ill shapes of the data sets and flattening to work with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: (60000, 784)\n",
      "Number of training labels: (60000,)\n",
      "Number of testing images: (10000, 784)\n",
      "Number of testing labels: (10000,)\n",
      "Number of training images: (60000, 784)\n",
      "Number of training labels: (60000, 1)\n",
      "Number of testing images: (10000, 784)\n",
      "Number of testing labels: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Initial dimensions of the vectors\n",
    "print('Number of training images:', X_train.shape)\n",
    "print('Number of training labels:', y_train.shape)\n",
    "\n",
    "print('Number of testing images:', X_test.shape)\n",
    "print('Number of testing labels:', y_test.shape)\n",
    "\n",
    "Y_train = (y_train.reshape((X_train.shape[0]),1))\n",
    "Y_test = (y_test.reshape((X_test.shape[0]),1))\n",
    "\n",
    "print('Number of training images:', X_train.shape)\n",
    "print('Number of training labels:', Y_train.shape)\n",
    "\n",
    "print('Number of testing images:', X_test.shape)\n",
    "print('Number of testing labels:', Y_test.shape)\n",
    "\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal 1 - nearest neighbour classifier (user made)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_lables = []\n",
    "for l in range(0, Y_test.shape[0]):\n",
    "    t = np.array([X_test[l]]*60000)\n",
    "    sub = X_train - t\n",
    "    sub = np.square(sub)\n",
    "    sub2 = np.sum(sub, 1)\n",
    "    inddd = np.argmin(sub2)\n",
    "    all_lables.append(Y_train[inddd])\n",
    "       \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is-  84.97\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "eff = 0\n",
    "for loop in range(0,Y_test.shape[0]):\n",
    "    if all_lables[loop]==Y_test[loop]:\n",
    "        eff = eff + 1\n",
    "print('The accuracy is- ',(eff*100)/Y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal nearest neighbour classifier (inbuilt function) Here all the experiments with the k number of components have been done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is-  85.54\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "eff = 0\n",
    "for loop in range(0,Y_test.shape[0]):\n",
    "    if y_pred[loop]==Y_test[loop]:\n",
    "        eff = eff + 1\n",
    "print('The accuracy is- ',(eff*100)/Y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying PCA to reduce the dimension from 784 to 50 and going through the same pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original train shape:    (60000, 784)\n",
      "transformed train shape: (60000, 100)\n",
      "0.9118044250550499\n",
      "original test shape:    (10000, 784)\n",
      "transformed test shape: (10000, 100)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "#pca.fit(X_train)\n",
    "X_pca_train = pca.fit_transform(X_train)\n",
    "print(\"original train shape:   \", X_train.shape)\n",
    "print(\"transformed train shape:\", X_pca_train.shape)\n",
    "print(np.sum(pca.explained_variance_ratio_))\n",
    "#pca.fit(X_test)\n",
    "X_pca_test = pca.transform(X_test)\n",
    "print(\"original test shape:   \", X_test.shape)\n",
    "print(\"transformed test shape:\", X_pca_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing after every 500 test samples have been labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n"
     ]
    }
   ],
   "source": [
    "all_lables_pca = []\n",
    "for l1 in range(0, Y_test.shape[0]):\n",
    "    t = np.array([X_pca_test[l1]]*60000)\n",
    "    sub = X_pca_train - t\n",
    "    sub = np.square(sub)\n",
    "    sub2 = np.sum(sub, 1)\n",
    "    trial = np.argmin(sub2)\n",
    "    all_lables_pca.append(Y_train[trial])\n",
    "    if l1%500 == 0:\n",
    "        print(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is-  84.82\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "eff = 0\n",
    "for loop in range(0,Y_test.shape[0]):\n",
    "    if all_lables_pca[loop]==Y_test[loop]:\n",
    "        eff = eff + 1\n",
    "print('The accuracy is- ',(eff*100)/Y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LDA to decrease the dimension from 50 to 9 by giving PCA as the input instead of the original data and going through the same pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original train shape:    (60000, 100)\n",
      "transformed train shape: (60000, 9)\n",
      "original test shape:    (10000, 100)\n",
      "transformed test shape: (10000, 9)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "X_lda_train = lda.fit_transform(X_pca_train,y_train)\n",
    "X_lda_test = lda.transform(X_pca_test)\n",
    "\n",
    "print(\"original train shape:   \", X_pca_train.shape)\n",
    "print(\"transformed train shape:\", X_lda_train.shape)\n",
    "\n",
    "print(\"original test shape:   \", X_pca_test.shape)\n",
    "print(\"transformed test shape:\", X_lda_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing after every 500 test samples have been labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n"
     ]
    }
   ],
   "source": [
    "all_lables_lda = []\n",
    "for l2 in range(0, Y_test.shape[0]):\n",
    "    t = np.array([X_lda_test[l2]]*60000)\n",
    "    sub = X_lda_train - t\n",
    "    sub = np.square(sub)\n",
    "    sub2 = np.sum(sub, 1)\n",
    "    trial = np.argmin(sub2)\n",
    "    all_lables_lda.append(Y_train[trial])\n",
    "    if l2%500 == 0:\n",
    "        print(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is-  79.06\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "eff = 0\n",
    "for loop in range(0,Y_test.shape[0]):\n",
    "    if all_lables_lda[loop]==Y_test[loop]:\n",
    "        eff = eff + 1\n",
    "print('The accuracy is- ',(eff*100)/Y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
